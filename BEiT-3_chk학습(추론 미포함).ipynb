{"cells":[{"cell_type":"markdown","source":["# 데이터 형식 변환"],"metadata":{"id":"PHQeqP1vFiNa"}},{"cell_type":"code","source":["# 드라이브 마운트\n","'''from google.colab import drive\n","drive.mount('/content/drive')'''"],"metadata":{"id":"x6Ya5JTNFnjg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import random\n","import pandas as pd\n","import os\n","\n","# 상대 경로 기반 파일 경로 설정\n","data_dir = \"./data\"\n","json_path = os.path.join(data_dir, \"dataset_v7w_telling.json\")\n","\n","# JSON 파일 로드\n","with open(json_path, \"r\", encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","# qa_pairs 가져오기\n","qa_pairs = []\n","if isinstance(data, dict):\n","    if \"qa_pairs\" in data:\n","        qa_pairs = data[\"qa_pairs\"]\n","    else:\n","        for k, v in data.items():\n","            if isinstance(v, list):\n","                for item in v:\n","                    if \"qa_pairs\" in item:\n","                        qa_pairs.extend(item[\"qa_pairs\"])\n","\n","print(\"총 QA pairs:\", len(qa_pairs))\n","\n","rows = []\n","\n","# enumerate로 순번 부여\n","for idx, q in enumerate(qa_pairs, start=1):\n","    # 4지선다 생성\n","    choices = q[\"multiple_choices\"].copy()\n","    if q[\"answer\"] not in choices:\n","        choices.append(q[\"answer\"])\n","    random.shuffle(choices)\n","\n","    # 정답 레이블\n","    answer_letter = None\n","    for i, c in enumerate(choices):\n","        if c == q[\"answer\"]:\n","            answer_letter = chr(65 + i)\n","            break\n","\n","    # 이미지 경로 (상대경로)\n","    image_id = q[\"image_id\"]\n","    img_path = f\"./images/v7w_{image_id}.jpg\"\n","\n","    # ID를 TRAIN_00001 이런 식으로 생성\n","    id_str = f\"TRAIN_{idx:05d}\"\n","\n","    rows.append({\n","        \"ID\": id_str,\n","        \"img_path\": img_path,\n","        \"Question\": q[\"question\"],\n","        \"A\": choices[0],\n","        \"B\": choices[1],\n","        \"C\": choices[2],\n","        \"D\": choices[3],\n","        \"answer\": answer_letter\n","    })\n","\n","df = pd.DataFrame(rows)\n","\n","# 예시 출력\n","print(df.head())\n","\n","# 상대경로로 CSV 저장\n","output_path = \"./visual7w_formatted.csv\"\n","df.to_csv(output_path, index=False)\n","print(f\"✅ CSV 저장 완료: {output_path}\")"],"metadata":{"id":"oE5dhDxiFrCu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BEiT-3"],"metadata":{"id":"ilGgur4jegfr"}},{"cell_type":"markdown","source":["## 라이브러리 import/설치"],"metadata":{"id":"DdSnfwFH8hC8"}},{"cell_type":"code","source":["!pip install -U requests==2.31.0"],"metadata":{"id":"j7uIwMMeM-y5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753313427344,"user_tz":-540,"elapsed":6316,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"0c09576c-e00c-43ea-cfeb-fc5539bf2c92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting requests==2.31.0\n","  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2025.7.14)\n","Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: requests\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.3\n","    Uninstalling requests-2.32.3:\n","      Successfully uninstalled requests-2.32.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed requests-2.31.0\n"]}]},{"cell_type":"code","source":["# git 설치\n","!pip install git+https://github.com/microsoft/torchscale.git"],"metadata":{"id":"fnPFNeyzxDYH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753313911678,"user_tz":-540,"elapsed":484332,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"b77e5ed6-59df-4a6e-c4cb-b54dd49fe00d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/microsoft/torchscale.git\n","  Cloning https://github.com/microsoft/torchscale.git to /tmp/pip-req-build-yhrwvh44\n","  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/torchscale.git /tmp/pip-req-build-yhrwvh44\n","  Resolved https://github.com/microsoft/torchscale.git to commit 4d1e0e82e5adf86dd424f1463192635b73fc8efc\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from torchscale==0.2.0) (2.6.0+cu124)\n","Collecting fairscale==0.4.0 (from torchscale==0.2.0)\n","  Downloading fairscale-0.4.0.tar.gz (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m60.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.6.13 (from torchscale==0.2.0)\n","  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from torchscale==0.2.0) (0.8.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13->torchscale==0.2.0) (0.21.0+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13->torchscale==0.2.0) (6.0.2)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13->torchscale==0.2.0) (0.33.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (2025.7.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->torchscale==0.2.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->torchscale==0.2.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->torchscale==0.2.0) (1.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (1.1.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->torchscale==0.2.0) (3.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.6.13->torchscale==0.2.0) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.6.13->torchscale==0.2.0) (11.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2025.7.14)\n","Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m139.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m177.2/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Exception:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n","    yield\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n","    data = self._fp_read(amt) if not fp_closed else b\"\"\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n","    return self._fp.read(amt) if amt is not None else self._fp.read()\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n","    data: bytes = self.__fp.read(amt)\n","                  ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/http/client.py\", line 473, in read\n","    s = self.fp.read(amt)\n","        ^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n","    return self._sock.recv_into(b)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n","    return self.read(nbytes, buffer)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n","    return self._sslobj.read(len, buffer)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","TimeoutError: The read operation timed out\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n","    requirement_set = resolver.resolve(\n","                      ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n","    self.factory.preparer.prepare_linked_requirements_more(reqs)\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 554, in prepare_linked_requirements_more\n","    self._complete_partial_requirements(\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 469, in _complete_partial_requirements\n","    for link, (filepath, _) in batch_download:\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/download.py\", line 184, in __call__\n","    for chunk in chunks:\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/progress_bars.py\", line 55, in _rich_progress_bar\n","    for chunk in iterable:\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n","    for chunk in response.raw.stream(\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n","    with self._error_catcher():\n","  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n","    self.gen.throw(typ, value, traceback)\n","  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n","    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n","pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install timm torchmetrics opencv-python"],"metadata":{"id":"aRTHV0EqxF3s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753313976262,"user_tz":-540,"elapsed":64580,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"e30c8232-a62b-4f17-c765-fa9e7f95903e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.17)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (25.0)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2025.7.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.7.14)\n","Downloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.8.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxN55bx_pFC8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753313976461,"user_tz":-540,"elapsed":195,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"8885e523-d28e-4140-adfe-add222eb9092"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 23 23:39:37 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0             44W /  400W |       0MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1puusXqpWJY"},"outputs":[],"source":["# 데이터 unzip\n","\n","!unzip -qq './data/visual7w_images.zip' -d '/content/'\n","!unzip -qq './data/open.zip' -d '/content/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bvk81qBrm7n7"},"outputs":[],"source":["# git clone은 최초 한번만 필요\n","\n","#!git clone https://github.com/hoon-bari/DACON_VQA.git\n","\n","# github_folder가 없다면 먼저 생성\n","\n","#!mkdir -p ./github_folder/DACON_VQA\n","\n","# beit3 폴더를 드라이브로 복사 (최초 1회 실행)\n","\n","#!cp -r ./DACON_VQA/BEiT-3 ./github_folder/DACON_VQA"]},{"cell_type":"code","source":["'''\n","git을 clone하고 수정했기에, git을 clone하지마시고\n","링크로 보내드린 githubfolder를 직접 로드해서 사용해주세요\n","'''\n","\n","%cd ./github_folder/DACON_VQA/BEiT-3"],"metadata":{"id":"-eEjWthdc08P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753314020315,"user_tz":-540,"elapsed":5,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"cadc8959-022b-47ff-d041-8f793ab87815"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt\n","\n","# tensorboardX는 선택사항\n","\n","!pip install -U tensorboardX"],"metadata":{"id":"BOY7t09Rc2Dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ki8FWEiqLCT"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import operator\n","import os\n","import string\n","import re\n","import random\n","import sys\n","import platform\n","import json\n","import shutil\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","\n","from PIL import Image\n","\n","from transformers import XLMRobertaTokenizer\n","\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG6jeHB77UD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753314054280,"user_tz":-540,"elapsed":6,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"fedf3e54-a315-4994-c119-5156d46266fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python Platform: Linux-6.1.123+-x86_64-with-glibc2.35\n","PyTorch Version: 2.6.0+cu124\n","\n","Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n","Pandas 2.2.2\n","GPU is available\n","Target device is cuda\n"]}],"source":["# 라이브러리 및 device 확인\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(f\"Python Platform: {platform.platform()}\")\n","print(f\"PyTorch Version: {torch.__version__}\")\n","print()\n","print(f\"Python {sys.version}\")\n","print(f\"Pandas {pd.__version__}\")\n","print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")\n","print(f\"Target device is {device}\")"]},{"cell_type":"markdown","source":["## CFG, data"],"metadata":{"id":"-OS9wn2W8ovn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NsncdFE7auS"},"outputs":[],"source":["# run_beit3_finetuning.py 파일 실행할 때 seed가 있긴 하지만, seed 고정\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(42) # Seed 고정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8E8v_X07clj"},"outputs":[],"source":["# 파일들을 불러옵니다.\n","\n","train_df = pd.read_csv('./data/visual7w_formatted.csv')\n","test_df = pd.read_csv('./test.csv')\n","sample_submission = pd.read_csv('./sample_submission.csv')\n","\n","train_img_path = './images'\n","test_img_path = './test_input_images'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XqeyJZ5FLhVe"},"outputs":[],"source":["# validation을 위해, train_df를 나눠줍시다.\n","\n","train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n","\n","# json_file 폴더를 하나 세션에 만듭시다.\n","\n","json_dir = './json_file'\n","os.makedirs(json_dir, exist_ok=True)"]},{"cell_type":"markdown","source":["## github_folder수정 (실행X)"],"metadata":{"id":"AsjtB3_F891Z"}},{"cell_type":"code","source":["# answer= i['answer'] -> answer = normalize_word(i['answer'])\\n\")\n","'''file_path = \"./github_folder/DACON_VQA/BEiT-3/datasets.py\"\n","\n","# 파일 읽기\n","with open(file_path, \"r\") as f:\n","    lines = f.readlines()\n","\n","# 내용 바꾸기\n","new_lines = []\n","for line in lines:\n","    if \"answer = i['answer']\" in line:\n","        # 작은따옴표에 맞춰서 교체\n","        new_lines.append(\"                    answer = normalize_word(i['answer'])\\n\")\n","    else:\n","        new_lines.append(line)\n","\n","# 파일 덮어쓰기\n","with open(file_path, \"w\") as f:\n","    f.writelines(new_lines)'''"],"metadata":{"id":"7Pkws7Cx9LZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4지선다이니까, class를 4로 고정\n","# modeling_finerune을 수정\n","'''# 원하는 클래스 수\n","num_classes = 4\n","\n","file_path = \"./github_folder/DACON_VQA/BEiT-3/modeling_finetune.py\"\n","\n","with open(file_path, \"r\") as f:\n","    lines = f.readlines()\n","\n","new_lines = []\n","for line in lines:\n","    if \"nn.Linear(embed_dim, num_classes)\" in line.replace(\" \", \"\"):\n","        print(\"✅ 기존 라인:\", line.strip())\n","        line = line.replace(\"num_classes\", str(num_classes))\n","        print(\"🔄 수정된 라인:\", line.strip())\n","    if \"nn.Linear(embed_dim*2,num_classes)\" in line.replace(\" \", \"\"):\n","        print(\"✅ 기존 라인:\", line.strip())\n","        line = line.replace(\"num_classes\", str(num_classes))\n","        print(\"🔄 수정된 라인:\", line.strip())\n","    new_lines.append(line)\n","\n","with open(file_path, \"w\") as f:\n","    f.writelines(new_lines)\n","\n","print(\"✅ 두 개의 Linear 레이어 출력 차원을\", num_classes, \"로 수정 완료.\")\n","\n","file_path = \"./github_folder/DACON_VQA/BEiT-3/modeling_finetune.py\"\n","\n","with open(file_path, \"r\") as f:\n","    lines = f.readlines()\n","\n","new_lines = []\n","for line in lines:\n","    # 117번 라인을 정확히 찾아서 바꾼다\n","    if \"self.head = nn.Linear\" in line and \"num_classes\" in line:\n","        print(\"✅ 기존 라인:\", line.strip())\n","        line = \"        self.head = nn.Linear(embed_dim, 4)\\n\"\n","        print(\"🔄 수정된 라인:\", line.strip())\n","    new_lines.append(line)\n","\n","with open(file_path, \"w\") as f:\n","    f.writelines(new_lines)\n","\n","print(\"✅ 117번 라인을 고정 완료.\")'''\n"],"metadata":{"id":"hWDEsDJ59PAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''file_path = \"./github_folder/DACON_VQA/BEiT-3/utils.py\"\n","\n","# 파일 읽기\n","with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","\n","# 수정하기\n","new_lines = []\n","for line in lines:\n","    if \"torch.load(ckpt_path, map_location='cpu')\" in line:\n","        new_line = \"    checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\\n\"\n","        new_lines.append(new_line)\n","    else:\n","        new_lines.append(line)\n","\n","# 덮어쓰기\n","with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(new_lines)\n","\n","# 변경 확인\n","print(\"✅ 수정 완료! 아래 라인이 잘 바뀌었는지 확인하세요:\")\n","for i, line in enumerate(new_lines, 1):\n","    if \"torch.load\" in line:\n","        print(f\"{i}: {line.strip()}\")'''\n"],"metadata":{"id":"JbxrmlOfsr2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''file_path = \"./github_folder/DACON_VQA/BEiT-3/utils.py\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","\n","new_lines = []\n","for i, line in enumerate(lines):\n","    # 잘못된 들여쓰기 라인 고치기\n","    if \"torch.load(ckpt_path, map_location='cpu', weights_only=False)\" in line:\n","        new_line = \"        checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)\\n\"\n","        new_lines.append(new_line)\n","    else:\n","        new_lines.append(line)\n","\n","with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(new_lines)\n","\n","print(\"✅ 들여쓰기 수정 완료!\")'''"],"metadata":{"id":"Vdzm9uR39VXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''file_path = \"./github_folder/DACON_VQA/BEiT-3/utils.py\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","\n","new_lines = []\n","for line in lines:\n","    if 'checkpoint = torch.load(args.resume' in line and 'weights_only' not in line:\n","        # weights_only=False를 추가\n","        fixed = line.replace(\"torch.load(args.resume\", \"torch.load(args.resume, weights_only=False\")\n","        new_lines.append(fixed)\n","    else:\n","        new_lines.append(line)\n","\n","with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(new_lines)\n","\n","print(\"✅ `weights_only=False` 수정 완료!\")'''\n"],"metadata":{"id":"5R1FNf7P9ekW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''file_path = \"./github_folder/DACON_VQA/BEiT-3/utils.py\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","\n","new_lines = []\n","for line in lines:\n","    if \"optimizer.load_state_dict\" in line:\n","        # Optimizer 로드를 주석 처리\n","        new_lines.append(\"# \" + line)\n","    else:\n","        new_lines.append(line)\n","\n","with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(new_lines)\n","\n","print(\"✅ optimizer.load_state_dict 주석 처리 완료\")'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753314055476,"user_tz":-540,"elapsed":22,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"b5591c03-1e98-4fd8-8f53-72cafd149b09","id":"L0x3-JOP9k1W"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'file_path = \"/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3/utils.py\"\\n\\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\\n    lines = f.readlines()\\n\\nnew_lines = []\\nfor line in lines:\\n    if \"optimizer.load_state_dict\" in line:\\n        # Optimizer 로드를 주석 처리\\n        new_lines.append(\"# \" + line)\\n    else:\\n        new_lines.append(line)\\n\\nwith open(file_path, \"w\", encoding=\"utf-8\") as f:\\n    f.writelines(new_lines)\\n\\nprint(\"✅ optimizer.load_state_dict 주석 처리 완료\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## model"],"metadata":{"id":"xkUw73Sq9OfV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgkSUoB49L-E"},"outputs":[],"source":["# BEIT-3 model을 fine-tuning 할때, json파일이 필요\n","# 데이터셋이 바뀔 때, 바뀌어야 되는 부분\n","\n","def make_mcq_json(df, out_path, is_train=False):\n","    mcq_data = []\n","    for _, r in df.iterrows():\n","        # ID → question_id\n","        num_part = re.findall(r'\\d+', r['ID'])[0]\n","        qid = f\"1{num_part}1\"\n","\n","        # img_path 로부터 파일명만 뽑고, 확장자(.jpg) 제거\n","        filename = os.path.basename(r['img_path'])  # e.g. \"TEST_000.jpg\"\n","        name, _ext  = os.path.splitext(filename)    # (\"TEST_000\", \".jpg\")\n","\n","        # 질문+보기 결합\n","        mcq = (\n","            r['Question']\n","            + \" Choices:\"\n","            + f\" A. {r['A']}\"\n","            + f\" B. {r['B']}\"\n","            + f\" C. {r['C']}\"\n","            + f\" D. {r['D']}\"\n","        )\n","\n","        entry = {\n","            \"image_id\":    name,    # <-- 확장자를 뗀 순수 파일명\n","            \"question\":    mcq,\n","            \"question_id\": qid,\n","        }\n","        if is_train:\n","            entry[\"answer\"] = r[\"answer\"]\n","        mcq_data.append(entry)\n","\n","    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n","    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(mcq_data, f, ensure_ascii=False, indent=2)\n","\n","\n","# 세션에 저장합니다.\n","\n","make_mcq_json(train_df, \"./json_file/train.json\", is_train=True)\n","make_mcq_json(val_df,   \"./json_file/val.json\", is_train=True)\n","make_mcq_json(test_df,  \"./json_file/test.json\", is_train=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrMwfSFEYTNU","outputId":"f12f2f2c-50da-49b4-f32c-b53c2e1a57cb","executionInfo":{"status":"ok","timestamp":1753314099397,"user_tz":-540,"elapsed":34517,"user":{"displayName":"이승현","userId":"09131068715081423692"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Write /content/vqa.train.jsonl with 118887 items !\n","Write /content/vqa.val.jsonl with 20981 items !\n","Write /content/vqa.test.jsonl with 852 items !\n","Contains 14539 image and 20981 pairs for val set!\n","Write /content/vqa.trainable_val.jsonl with 19567 items !\n","Write /content/vqa.rest_val.jsonl with 1414 items !\n"]}],"source":["# BEIT-3 모델이 학습하는 형식에 맞게 index를 만드는 코드\n","\n","#CustomDataset\n","import importlib.util\n","\n","spec = importlib.util.spec_from_file_location(\n","    \"datasets\",\n","    \"./github_folder/DACON_VQA/BEiT-3/datasets.py\"\n",")\n","datasets = importlib.util.module_from_spec(spec)\n","spec.loader.exec_module(datasets)\n","\n","CustomDataset = datasets.CustomDataset\n","\n","from transformers import XLMRobertaTokenizer\n","\n","tokenizer = XLMRobertaTokenizer(\"./github_folder/model_file/beit3.spm\")\n","\n","CustomDataset.make_dataset_index(\n","    data_path=\".\",\n","    tokenizer=tokenizer,\n","    json_data_path=\"./json_file/\",\n",")"]},{"cell_type":"code","source":["!mkdir -p ./train\n","!cp ./images/*.jpg ./train/"],"metadata":{"id":"PzuCR-OgWRN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 경로 설정\n","model_dir = \".\"\n","model_file = f\"{model_dir}/finetuned_model_file\"\n","\n","# 최초 pretrained checkpoint 경로 (처음부터 학습이면 이 경로 사용)\n","model_ckpt = f\"{model_dir}/github_folder/model_file/beit3_large_indomain_patch16_480_vqa.pth\"\n","\n","# 학습 실행\n","# 총 5 eopch 학습\n","# colab 런타임 시간 제한 때문에, resume 사용\n","# checkpoint-0,1,2,3 이런식으로 한 epoch씩 끊어서 학습\n","!python ./github_folder/DACON_VQA/BEiT-3/run_beit3_finetuning.py \\\n","    --model beit3_large_patch16_480_vqacustom \\\n","    --input_size 480 \\\n","    --task vqacustom \\\n","    --batch_size 64 \\\n","    --layer_decay 1.0 \\\n","    --lr 2e-5 \\\n","    --update_freq 1 \\\n","    --randaug \\\n","    --epochs 5 \\\n","    --resume ./finetuned_model_file/checkpoint-3.pth \\\n","    --warmup_epochs 0 \\\n","    --drop_path 0.15 \\\n","    --sentencepiece_model ./github_folder/model_file/beit3.spm \\\n","    --finetune {model_ckpt} \\\n","    --data_path . \\\n","    --output_dir {model_file}/ \\\n","    --log_dir {model_file}/log \\\n","    --weight_decay 0.01 \\\n","    --num_max_bpe_tokens 128 \\\n","    --nb_classes 4 \\\n","    --seed 42 \\\n","    --save_ckpt_freq 1 \\\n","    --task_head_lr_weight 20 \\\n","    --opt_betas 0.9 0.98 \\\n","    --checkpoint_activations\n"],"metadata":{"id":"K_UN00SpAImT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9b63048-f5f4-4104-ff0b-d08b845bca1a","executionInfo":{"status":"ok","timestamp":1753330040542,"user_tz":-540,"elapsed":15936849,"user":{"displayName":"이승현","userId":"09131068715081423692"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Not using distributed mode\n","Namespace(model='beit3_large_patch16_480_vqacustom', task='vqacustom', input_size=480, drop_path=0.15, checkpoint_activations=True, sentencepiece_model='/content/drive/MyDrive/멀티모달/github_folder/model_file/beit3.spm', vocab_size=64010, num_max_bpe_tokens=128, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.98], clip_grad=None, momentum=0.9, weight_decay=0.01, lr=2e-05, layer_decay=1.0, task_head_lr_weight=20.0, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=0, warmup_steps=-1, batch_size=64, eval_batch_size=None, epochs=5, update_freq=1, save_ckpt_freq=1, randaug=True, train_interpolation='bicubic', finetune='/content/drive/MyDrive/멀티모달/github_folder/model_file/beit3_large_indomain_patch16_480_vqa.pth', model_key='model|module', model_prefix='', data_path='/content/', output_dir='/content/drive/MyDrive/멀티모달/finetuned_model_file/', log_dir='/content/drive/MyDrive/멀티모달/finetuned_model_file/log', device='cuda', seed=42, resume='/content/drive/MyDrive/멀티모달/finetuned_model_file/checkpoint-3.pth', auto_resume=True, save_ckpt=True, start_epoch=0, eval=False, dist_eval=False, num_workers=0, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', task_cache_path='/content/drive/MyDrive/멀티모달/finetuned_model_file/', nb_classes=4, mixup=0, cutmix=0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, captioning_mask_prob=0.6, drop_worst_ratio=0.2, drop_worst_after=12000, num_beams=3, length_penalty=0.6, label_smoothing=0.1, enable_deepspeed=False, initial_scale_power=16, zero_stage=0, distributed=False)\n","Load 118887 image-text pairs from /content/vqa.train.jsonl. \n","Load 19567 image-text pairs from /content/vqa.trainable_val.jsonl. \n","Load 1414 image-text pairs from /content/vqa.rest_val.jsonl. \n","model_config = beit3_large_patch16_480_vqacustom\n","Load ckpt from /content/drive/MyDrive/멀티모달/github_folder/model_file/beit3_large_indomain_patch16_480_vqa.pth\n","Load state_dict by model_key = model\n","size mismatch for head.3.weight: copying a param with shape torch.Size([3129, 2048]) from checkpoint, the shape in current model is torch.Size([4, 2048]).\n","size mismatch for head.3.bias: copying a param with shape torch.Size([3129]) from checkpoint, the shape in current model is torch.Size([4]).\n","Model = BEiT3ForVisualQuestionAnswering(\n","  (beit3): BEiT3(\n","    (text_embed): TextEmbedding(64010, 1024)\n","    (vision_embed): VisionEmbedding(\n","      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n","    )\n","    (encoder): Encoder(\n","      (dropout_module): Dropout(p=0.0, inplace=False)\n","      (embed_positions): MutliwayEmbedding(\n","        (A): PositionalEmbedding(903, 1024)\n","        (B): PositionalEmbedding(1024, 1024)\n","      )\n","      (layers): ModuleList(\n","        (0): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.0)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (1): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.006521739130434782)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (2): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.013043478260869565)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (3): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.019565217391304346)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (4): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.02608695652173913)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (5): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.03260869565217391)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (6): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.03913043478260869)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (7): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.04565217391304348)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (8): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.05217391304347826)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (9): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.05869565217391304)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (10): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.06521739130434782)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (11): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.07173913043478261)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (12): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.07826086956521738)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (13): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.08478260869565217)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (14): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.09130434782608696)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (15): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.09782608695652173)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (16): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.10434782608695652)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (17): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.1108695652173913)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (18): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.11739130434782608)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (19): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.12391304347826086)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (20): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.13043478260869565)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (21): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.13695652173913042)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (22): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.14347826086956522)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (23): EncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (k_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (q_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (out_proj): MultiwayNetwork(\n","              (A): Linear(in_features=1024, out_features=1024, bias=True)\n","              (B): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (inner_attn_ln): MultiwayNetwork(\n","              (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (dropout_module): Dropout(p=0.0, inplace=False)\n","          )\n","          (self_attn_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (dropout_module): Dropout(p=0.0, inplace=False)\n","          (drop_path): DropPath(p=0.15)\n","          (ffn): MultiwayNetwork(\n","            (A): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (B): FeedForwardNetwork(\n","              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n","              (dropout_module): Dropout(p=0.0, inplace=False)\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (final_layer_norm): MultiwayNetwork(\n","            (A): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (B): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (pooler): Pooler(\n","    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (activation): Tanh()\n","  )\n","  (head): Sequential(\n","    (0): Linear(in_features=1024, out_features=2048, bias=True)\n","    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","    (2): GELU(approximate='none')\n","    (3): Linear(in_features=2048, out_features=4, bias=True)\n","  )\n",")\n","number of params: 676582404\n","LR = 0.00002000\n","Batch size = 64\n","Update frequent = 1\n","Number of training examples = 138454\n","Number of training training per epoch = 2163\n","Assigned values = [1.0, 20.0]\n","Param groups = {\n","  \"layer_0_decay\": {\n","    \"weight_decay\": 0.01,\n","    \"params\": [\n","      \"beit3.text_embed.weight\",\n","      \"beit3.vision_embed.mask_token\",\n","      \"beit3.vision_embed.proj.weight\",\n","      \"beit3.encoder.embed_positions.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.0.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.0.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.0.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.0.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.1.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.1.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.1.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.1.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.1.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.1.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.1.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.1.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.2.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.2.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.2.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.2.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.2.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.2.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.2.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.2.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.3.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.3.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.3.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.3.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.3.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.3.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.3.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.3.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.4.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.4.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.4.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.4.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.4.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.4.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.4.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.4.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.5.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.5.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.5.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.5.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.5.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.5.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.5.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.5.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.6.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.6.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.6.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.6.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.6.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.6.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.6.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.6.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.7.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.7.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.7.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.7.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.7.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.7.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.7.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.7.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.8.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.8.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.8.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.8.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.8.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.8.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.8.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.8.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.9.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.9.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.9.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.9.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.9.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.9.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.9.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.9.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.10.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.10.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.10.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.10.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.10.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.10.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.10.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.10.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.11.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.11.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.11.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.11.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.11.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.11.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.11.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.11.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.12.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.12.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.12.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.12.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.12.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.12.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.12.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.12.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.13.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.13.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.13.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.13.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.13.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.13.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.13.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.13.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.14.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.14.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.14.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.14.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.14.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.14.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.14.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.14.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.15.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.15.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.15.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.15.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.15.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.15.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.15.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.15.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.16.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.16.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.16.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.16.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.16.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.16.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.16.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.16.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.17.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.17.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.17.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.17.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.17.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.17.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.17.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.17.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.18.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.18.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.18.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.18.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.18.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.18.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.18.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.18.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.19.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.19.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.19.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.19.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.19.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.19.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.19.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.19.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.20.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.20.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.20.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.20.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.20.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.20.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.20.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.20.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.21.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.21.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.21.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.21.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.21.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.21.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.21.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.21.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.22.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.22.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.22.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.22.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.22.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.22.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.22.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.22.ffn.B.fc2.weight\",\n","      \"beit3.encoder.layers.23.self_attn.k_proj.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn.k_proj.B.weight\",\n","      \"beit3.encoder.layers.23.self_attn.v_proj.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn.v_proj.B.weight\",\n","      \"beit3.encoder.layers.23.self_attn.q_proj.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn.q_proj.B.weight\",\n","      \"beit3.encoder.layers.23.self_attn.out_proj.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn.out_proj.B.weight\",\n","      \"beit3.encoder.layers.23.ffn.A.fc1.weight\",\n","      \"beit3.encoder.layers.23.ffn.A.fc2.weight\",\n","      \"beit3.encoder.layers.23.ffn.B.fc1.weight\",\n","      \"beit3.encoder.layers.23.ffn.B.fc2.weight\",\n","      \"pooler.dense.weight\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"layer_0_no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"beit3.vision_embed.cls_token\",\n","      \"beit3.vision_embed.proj.bias\",\n","      \"beit3.encoder.embed_positions.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.0.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.0.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.0.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.0.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.0.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.0.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.0.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.0.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.0.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.0.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.0.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.0.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.0.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.0.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.0.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.0.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.0.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.1.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.1.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.1.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.1.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.1.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.1.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.1.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.1.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.1.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.1.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.1.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.1.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.1.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.1.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.1.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.2.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.2.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.2.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.2.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.2.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.2.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.2.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.2.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.2.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.2.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.2.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.2.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.2.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.2.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.2.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.3.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.3.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.3.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.3.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.3.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.3.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.3.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.3.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.3.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.3.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.3.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.3.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.3.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.3.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.3.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.4.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.4.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.4.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.4.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.4.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.4.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.4.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.4.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.4.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.4.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.4.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.4.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.4.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.4.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.4.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.5.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.5.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.5.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.5.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.5.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.5.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.5.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.5.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.5.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.5.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.5.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.5.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.5.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.5.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.5.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.6.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.6.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.6.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.6.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.6.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.6.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.6.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.6.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.6.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.6.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.6.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.6.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.6.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.6.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.6.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.7.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.7.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.7.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.7.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.7.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.7.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.7.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.7.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.7.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.7.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.7.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.7.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.7.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.7.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.7.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.8.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.8.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.8.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.8.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.8.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.8.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.8.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.8.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.8.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.8.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.8.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.8.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.8.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.8.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.8.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.9.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.9.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.9.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.9.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.9.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.9.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.9.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.9.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.9.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.9.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.9.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.9.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.9.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.9.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.9.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.10.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.10.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.10.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.10.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.10.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.10.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.10.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.10.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.10.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.10.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.10.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.10.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.10.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.10.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.10.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.11.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.11.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.11.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.11.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.11.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.11.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.11.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.11.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.11.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.11.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.11.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.11.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.11.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.11.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.11.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.12.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.12.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.12.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.12.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.12.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.12.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.12.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.12.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.12.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.12.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.12.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.12.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.12.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.12.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.12.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.12.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.12.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.13.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.13.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.13.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.13.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.13.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.13.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.13.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.13.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.13.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.13.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.13.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.13.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.13.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.13.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.13.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.13.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.13.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.14.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.14.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.14.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.14.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.14.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.14.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.14.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.14.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.14.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.14.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.14.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.14.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.14.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.14.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.14.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.14.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.14.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.15.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.15.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.15.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.15.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.15.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.15.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.15.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.15.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.15.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.15.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.15.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.15.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.15.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.15.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.15.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.15.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.15.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.16.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.16.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.16.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.16.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.16.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.16.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.16.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.16.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.16.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.16.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.16.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.16.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.16.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.16.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.16.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.16.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.16.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.17.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.17.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.17.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.17.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.17.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.17.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.17.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.17.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.17.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.17.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.17.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.17.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.17.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.17.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.17.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.17.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.17.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.18.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.18.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.18.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.18.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.18.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.18.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.18.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.18.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.18.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.18.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.18.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.18.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.18.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.18.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.18.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.18.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.18.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.19.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.19.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.19.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.19.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.19.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.19.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.19.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.19.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.19.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.19.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.19.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.19.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.19.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.19.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.19.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.19.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.19.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.20.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.20.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.20.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.20.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.20.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.20.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.20.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.20.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.20.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.20.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.20.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.20.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.20.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.20.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.20.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.20.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.20.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.21.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.21.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.21.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.21.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.21.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.21.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.21.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.21.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.21.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.21.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.21.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.21.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.21.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.21.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.21.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.21.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.21.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.22.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.22.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.22.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.22.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.22.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.22.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.22.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.22.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.22.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.22.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.22.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.22.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.22.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.22.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.22.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.22.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.22.final_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn.k_proj.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn.k_proj.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn.v_proj.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn.v_proj.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn.q_proj.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn.q_proj.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn.out_proj.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn.out_proj.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn.inner_attn_ln.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn.inner_attn_ln.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn.inner_attn_ln.B.weight\",\n","      \"beit3.encoder.layers.23.self_attn.inner_attn_ln.B.bias\",\n","      \"beit3.encoder.layers.23.self_attn_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.23.self_attn_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.23.self_attn_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.23.self_attn_layer_norm.B.bias\",\n","      \"beit3.encoder.layers.23.ffn.A.fc1.bias\",\n","      \"beit3.encoder.layers.23.ffn.A.fc2.bias\",\n","      \"beit3.encoder.layers.23.ffn.A.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.23.ffn.A.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.23.ffn.B.fc1.bias\",\n","      \"beit3.encoder.layers.23.ffn.B.fc2.bias\",\n","      \"beit3.encoder.layers.23.ffn.B.ffn_layernorm.weight\",\n","      \"beit3.encoder.layers.23.ffn.B.ffn_layernorm.bias\",\n","      \"beit3.encoder.layers.23.final_layer_norm.A.weight\",\n","      \"beit3.encoder.layers.23.final_layer_norm.A.bias\",\n","      \"beit3.encoder.layers.23.final_layer_norm.B.weight\",\n","      \"beit3.encoder.layers.23.final_layer_norm.B.bias\",\n","      \"pooler.norm.weight\",\n","      \"pooler.norm.bias\",\n","      \"pooler.dense.bias\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"layer_1_decay\": {\n","    \"weight_decay\": 0.01,\n","    \"params\": [\n","      \"head.0.weight\",\n","      \"head.3.weight\"\n","    ],\n","    \"lr_scale\": 20.0\n","  },\n","  \"layer_1_no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"head.0.bias\",\n","      \"head.1.weight\",\n","      \"head.1.bias\",\n","      \"head.3.bias\"\n","    ],\n","    \"lr_scale\": 20.0\n","  }\n","}\n","/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3/utils.py:379: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self._scaler = torch.cuda.amp.GradScaler()\n","Set warmup steps = 0\n","Resume checkpoint /content/drive/MyDrive/멀티모달/finetuned_model_file/checkpoint-3.pth\n","With optim & sched!\n","Start training for 5 epochs\n","/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3/engine_for_finetuning.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","/usr/local/lib/python3.11/dist-packages/fairscale/nn/checkpoint/checkpoint_activations.py:216: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled):\n","Epoch: [4]  [   0/2163]  eta: 5:21:19  lr: 0.000056  min_lr: 0.000003  loss: 0.1422 (0.1422)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 6.0751 (6.0751)  time: 8.9134  data: 0.9211  max mem: 25146\n","/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3/randaug.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","Epoch: [4]  [  10/2163]  eta: 4:25:17  lr: 0.000056  min_lr: 0.000003  loss: 0.1798 (0.2092)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 13.0439 (11.8940)  time: 7.3934  data: 0.7105  max mem: 30315\n","Epoch: [4]  [  20/2163]  eta: 4:21:19  lr: 0.000056  min_lr: 0.000003  loss: 0.1798 (0.2103)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.2545 (11.5859)  time: 7.2368  data: 0.6841  max mem: 30315\n","Epoch: [4]  [  30/2163]  eta: 4:18:33  lr: 0.000055  min_lr: 0.000003  loss: 0.2033 (0.2354)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.2545 (12.0755)  time: 7.2066  data: 0.6530  max mem: 30315\n","Epoch: [4]  [  40/2163]  eta: 4:16:53  lr: 0.000055  min_lr: 0.000003  loss: 0.3254 (0.2676)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 13.3592 (13.1532)  time: 7.2007  data: 0.6464  max mem: 30315\n","Epoch: [4]  [  50/2163]  eta: 4:15:14  lr: 0.000055  min_lr: 0.000003  loss: 0.3254 (0.2738)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 14.1832 (13.3282)  time: 7.2085  data: 0.6539  max mem: 30315\n","Epoch: [4]  [  60/2163]  eta: 4:13:45  lr: 0.000054  min_lr: 0.000003  loss: 0.3045 (0.2827)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 14.1832 (13.8305)  time: 7.1990  data: 0.6444  max mem: 30315\n","Epoch: [4]  [  70/2163]  eta: 4:12:21  lr: 0.000054  min_lr: 0.000003  loss: 0.2636 (0.2782)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.3267 (13.5305)  time: 7.2009  data: 0.6462  max mem: 30315\n","Epoch: [4]  [  80/2163]  eta: 4:11:00  lr: 0.000054  min_lr: 0.000003  loss: 0.2379 (0.2782)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.9046 (13.2000)  time: 7.2002  data: 0.6455  max mem: 30315\n","Epoch: [4]  [  90/2163]  eta: 4:09:44  lr: 0.000053  min_lr: 0.000003  loss: 0.2207 (0.2738)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.4001 (12.9742)  time: 7.2062  data: 0.6512  max mem: 30315\n","Epoch: [4]  [ 100/2163]  eta: 4:08:22  lr: 0.000053  min_lr: 0.000003  loss: 0.2319 (0.2790)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6564 (13.0586)  time: 7.1980  data: 0.6429  max mem: 30315\n","Epoch: [4]  [ 110/2163]  eta: 4:07:07  lr: 0.000053  min_lr: 0.000003  loss: 0.2801 (0.2771)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8520 (12.8227)  time: 7.1944  data: 0.6392  max mem: 30315\n","Epoch: [4]  [ 120/2163]  eta: 4:05:52  lr: 0.000052  min_lr: 0.000003  loss: 0.1863 (0.2715)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5881 (12.6372)  time: 7.2065  data: 0.6515  max mem: 30315\n","Epoch: [4]  [ 130/2163]  eta: 4:04:37  lr: 0.000052  min_lr: 0.000003  loss: 0.2084 (0.2738)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4509 (12.6908)  time: 7.2058  data: 0.6509  max mem: 30315\n","Epoch: [4]  [ 140/2163]  eta: 4:03:23  lr: 0.000052  min_lr: 0.000003  loss: 0.2160 (0.2693)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.5494 (12.6154)  time: 7.2054  data: 0.6505  max mem: 30315\n","Epoch: [4]  [ 150/2163]  eta: 4:02:08  lr: 0.000052  min_lr: 0.000003  loss: 0.1989 (0.2688)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1818 (12.6166)  time: 7.2037  data: 0.6486  max mem: 30315\n","Epoch: [4]  [ 160/2163]  eta: 4:00:57  lr: 0.000051  min_lr: 0.000003  loss: 0.2428 (0.2695)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4603 (12.5865)  time: 7.2107  data: 0.6555  max mem: 30315\n","Epoch: [4]  [ 170/2163]  eta: 3:59:42  lr: 0.000051  min_lr: 0.000003  loss: 0.2372 (0.2659)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4603 (12.5610)  time: 7.2083  data: 0.6532  max mem: 30315\n","Epoch: [4]  [ 180/2163]  eta: 3:58:28  lr: 0.000051  min_lr: 0.000003  loss: 0.1922 (0.2643)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.5167 (12.4998)  time: 7.1978  data: 0.6430  max mem: 30315\n","Epoch: [4]  [ 190/2163]  eta: 3:57:14  lr: 0.000050  min_lr: 0.000003  loss: 0.2234 (0.2660)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.8919 (12.6286)  time: 7.1999  data: 0.6448  max mem: 30315\n","Epoch: [4]  [ 200/2163]  eta: 3:56:02  lr: 0.000050  min_lr: 0.000003  loss: 0.2257 (0.2672)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.3776 (12.5813)  time: 7.2072  data: 0.6521  max mem: 30315\n","Epoch: [4]  [ 210/2163]  eta: 3:54:49  lr: 0.000050  min_lr: 0.000002  loss: 0.2213 (0.2644)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.6756 (12.4430)  time: 7.2080  data: 0.6527  max mem: 30315\n","Epoch: [4]  [ 220/2163]  eta: 3:53:36  lr: 0.000049  min_lr: 0.000002  loss: 0.1923 (0.2617)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.0781 (12.2254)  time: 7.2059  data: 0.6505  max mem: 30315\n","Epoch: [4]  [ 230/2163]  eta: 3:52:23  lr: 0.000049  min_lr: 0.000002  loss: 0.2366 (0.2651)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.2941 (12.2161)  time: 7.2064  data: 0.6514  max mem: 30315\n","Epoch: [4]  [ 240/2163]  eta: 3:51:12  lr: 0.000049  min_lr: 0.000002  loss: 0.3043 (0.2665)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.3152 (12.2884)  time: 7.2142  data: 0.6592  max mem: 30315\n","Epoch: [4]  [ 250/2163]  eta: 3:49:59  lr: 0.000049  min_lr: 0.000002  loss: 0.2374 (0.2658)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.5993 (12.2448)  time: 7.2140  data: 0.6589  max mem: 30315\n","Epoch: [4]  [ 260/2163]  eta: 3:48:46  lr: 0.000048  min_lr: 0.000002  loss: 0.2159 (0.2641)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7438 (12.2078)  time: 7.2012  data: 0.6463  max mem: 30315\n","Epoch: [4]  [ 270/2163]  eta: 3:47:34  lr: 0.000048  min_lr: 0.000002  loss: 0.2224 (0.2646)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7438 (12.1721)  time: 7.2068  data: 0.6516  max mem: 30315\n","Epoch: [4]  [ 280/2163]  eta: 3:46:25  lr: 0.000048  min_lr: 0.000002  loss: 0.2654 (0.2642)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5448 (12.2357)  time: 7.2389  data: 0.6838  max mem: 30315\n","Epoch: [4]  [ 290/2163]  eta: 3:45:13  lr: 0.000047  min_lr: 0.000002  loss: 0.2466 (0.2649)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8835 (12.2130)  time: 7.2396  data: 0.6847  max mem: 30315\n","Epoch: [4]  [ 300/2163]  eta: 3:43:59  lr: 0.000047  min_lr: 0.000002  loss: 0.2323 (0.2641)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.1953 (12.2564)  time: 7.2026  data: 0.6475  max mem: 30315\n","Epoch: [4]  [ 310/2163]  eta: 3:42:47  lr: 0.000047  min_lr: 0.000002  loss: 0.2005 (0.2628)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.4360 (12.2261)  time: 7.1993  data: 0.6439  max mem: 30315\n","Epoch: [4]  [ 320/2163]  eta: 3:41:35  lr: 0.000047  min_lr: 0.000002  loss: 0.2002 (0.2619)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.2336 (12.2466)  time: 7.2130  data: 0.6576  max mem: 30315\n","Epoch: [4]  [ 330/2163]  eta: 3:40:22  lr: 0.000046  min_lr: 0.000002  loss: 0.2628 (0.2625)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.3260 (12.3200)  time: 7.2061  data: 0.6511  max mem: 30315\n","Epoch: [4]  [ 340/2163]  eta: 3:39:09  lr: 0.000046  min_lr: 0.000002  loss: 0.2628 (0.2623)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.3579 (12.3213)  time: 7.1990  data: 0.6439  max mem: 30315\n","Epoch: [4]  [ 350/2163]  eta: 3:37:57  lr: 0.000046  min_lr: 0.000002  loss: 0.2196 (0.2627)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.9718 (12.2868)  time: 7.2101  data: 0.6551  max mem: 30315\n","Epoch: [4]  [ 360/2163]  eta: 3:36:45  lr: 0.000045  min_lr: 0.000002  loss: 0.2594 (0.2643)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.3078 (12.2940)  time: 7.2162  data: 0.6613  max mem: 30315\n","Epoch: [4]  [ 370/2163]  eta: 3:35:33  lr: 0.000045  min_lr: 0.000002  loss: 0.2520 (0.2637)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3040 (12.2598)  time: 7.2131  data: 0.6579  max mem: 30315\n","Epoch: [4]  [ 380/2163]  eta: 3:34:20  lr: 0.000045  min_lr: 0.000002  loss: 0.2294 (0.2636)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1409 (12.3015)  time: 7.2081  data: 0.6527  max mem: 30315\n","Epoch: [4]  [ 390/2163]  eta: 3:33:08  lr: 0.000045  min_lr: 0.000002  loss: 0.2616 (0.2637)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 13.0737 (12.2942)  time: 7.2079  data: 0.6527  max mem: 30315\n","Epoch: [4]  [ 400/2163]  eta: 3:31:57  lr: 0.000044  min_lr: 0.000002  loss: 0.3530 (0.2658)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 13.0737 (12.3056)  time: 7.2195  data: 0.6642  max mem: 30315\n","Epoch: [4]  [ 410/2163]  eta: 3:30:45  lr: 0.000044  min_lr: 0.000002  loss: 0.2929 (0.2662)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.8141 (12.2709)  time: 7.2235  data: 0.6682  max mem: 30315\n","Epoch: [4]  [ 420/2163]  eta: 3:29:32  lr: 0.000044  min_lr: 0.000002  loss: 0.1947 (0.2645)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0619 (12.2157)  time: 7.2114  data: 0.6566  max mem: 30315\n","Epoch: [4]  [ 430/2163]  eta: 3:28:20  lr: 0.000044  min_lr: 0.000002  loss: 0.2089 (0.2647)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1617 (12.2436)  time: 7.2091  data: 0.6542  max mem: 30315\n","Epoch: [4]  [ 440/2163]  eta: 3:27:08  lr: 0.000043  min_lr: 0.000002  loss: 0.2532 (0.2650)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7754 (12.2188)  time: 7.2106  data: 0.6555  max mem: 30315\n","Epoch: [4]  [ 450/2163]  eta: 3:25:55  lr: 0.000043  min_lr: 0.000002  loss: 0.2231 (0.2645)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.4625 (12.1349)  time: 7.2101  data: 0.6548  max mem: 30315\n","Epoch: [4]  [ 460/2163]  eta: 3:24:44  lr: 0.000043  min_lr: 0.000002  loss: 0.2186 (0.2647)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.1432 (12.1747)  time: 7.2179  data: 0.6622  max mem: 30315\n","Epoch: [4]  [ 470/2163]  eta: 3:23:31  lr: 0.000043  min_lr: 0.000002  loss: 0.1929 (0.2635)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8865 (12.1558)  time: 7.2151  data: 0.6595  max mem: 30315\n","Epoch: [4]  [ 480/2163]  eta: 3:22:20  lr: 0.000042  min_lr: 0.000002  loss: 0.1818 (0.2625)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.6091 (12.1056)  time: 7.2148  data: 0.6594  max mem: 30315\n","Epoch: [4]  [ 490/2163]  eta: 3:21:07  lr: 0.000042  min_lr: 0.000002  loss: 0.1909 (0.2630)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0117 (12.1073)  time: 7.2099  data: 0.6546  max mem: 30315\n","Epoch: [4]  [ 500/2163]  eta: 3:19:55  lr: 0.000042  min_lr: 0.000002  loss: 0.2560 (0.2633)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4785 (12.1145)  time: 7.2036  data: 0.6482  max mem: 30315\n","Epoch: [4]  [ 510/2163]  eta: 3:18:43  lr: 0.000041  min_lr: 0.000002  loss: 0.2653 (0.2637)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4389 (12.0958)  time: 7.2247  data: 0.6695  max mem: 30315\n","Epoch: [4]  [ 520/2163]  eta: 3:17:31  lr: 0.000041  min_lr: 0.000002  loss: 0.2827 (0.2637)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.5049 (12.0881)  time: 7.2281  data: 0.6729  max mem: 30315\n","Epoch: [4]  [ 530/2163]  eta: 3:16:20  lr: 0.000041  min_lr: 0.000002  loss: 0.2900 (0.2652)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 14.0411 (12.1206)  time: 7.2246  data: 0.6692  max mem: 30315\n","Epoch: [4]  [ 540/2163]  eta: 3:15:08  lr: 0.000041  min_lr: 0.000002  loss: 0.3018 (0.2653)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.8847 (12.1117)  time: 7.2234  data: 0.6680  max mem: 30315\n","Epoch: [4]  [ 550/2163]  eta: 3:13:55  lr: 0.000040  min_lr: 0.000002  loss: 0.2371 (0.2646)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.1749 (12.0615)  time: 7.2099  data: 0.6545  max mem: 30315\n","Epoch: [4]  [ 560/2163]  eta: 3:12:43  lr: 0.000040  min_lr: 0.000002  loss: 0.2138 (0.2652)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.5851 (12.0711)  time: 7.2092  data: 0.6513  max mem: 30315\n","Epoch: [4]  [ 570/2163]  eta: 3:11:31  lr: 0.000040  min_lr: 0.000002  loss: 0.2138 (0.2654)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8927 (12.0349)  time: 7.2071  data: 0.6494  max mem: 30315\n","Epoch: [4]  [ 580/2163]  eta: 3:10:19  lr: 0.000040  min_lr: 0.000002  loss: 0.2106 (0.2661)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3974 (11.9996)  time: 7.2147  data: 0.6597  max mem: 30315\n","Epoch: [4]  [ 590/2163]  eta: 3:09:07  lr: 0.000039  min_lr: 0.000002  loss: 0.2111 (0.2665)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0580 (11.9896)  time: 7.2273  data: 0.6721  max mem: 30315\n","Epoch: [4]  [ 600/2163]  eta: 3:07:55  lr: 0.000039  min_lr: 0.000002  loss: 0.2114 (0.2665)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8746 (11.9577)  time: 7.2179  data: 0.6627  max mem: 30315\n","Epoch: [4]  [ 610/2163]  eta: 3:06:43  lr: 0.000039  min_lr: 0.000002  loss: 0.2500 (0.2667)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8746 (11.9451)  time: 7.2116  data: 0.6565  max mem: 30315\n","Epoch: [4]  [ 620/2163]  eta: 3:05:30  lr: 0.000039  min_lr: 0.000002  loss: 0.2500 (0.2666)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6544 (11.9169)  time: 7.2038  data: 0.6486  max mem: 30315\n","Epoch: [4]  [ 630/2163]  eta: 3:04:18  lr: 0.000039  min_lr: 0.000002  loss: 0.2533 (0.2666)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.6485 (11.8920)  time: 7.1984  data: 0.6435  max mem: 30315\n","Epoch: [4]  [ 640/2163]  eta: 3:03:06  lr: 0.000038  min_lr: 0.000002  loss: 0.2784 (0.2664)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.2382 (11.8697)  time: 7.2092  data: 0.6542  max mem: 30315\n","Epoch: [4]  [ 650/2163]  eta: 3:01:54  lr: 0.000038  min_lr: 0.000002  loss: 0.2776 (0.2668)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8353 (11.9212)  time: 7.2189  data: 0.6640  max mem: 30315\n","Epoch: [4]  [ 660/2163]  eta: 3:00:41  lr: 0.000038  min_lr: 0.000002  loss: 0.2587 (0.2664)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8353 (11.8974)  time: 7.2096  data: 0.6548  max mem: 30315\n","Epoch: [4]  [ 670/2163]  eta: 2:59:29  lr: 0.000038  min_lr: 0.000002  loss: 0.2587 (0.2668)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.6717 (11.9147)  time: 7.2032  data: 0.6494  max mem: 30315\n","Epoch: [4]  [ 680/2163]  eta: 2:58:17  lr: 0.000037  min_lr: 0.000002  loss: 0.2484 (0.2667)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1584 (11.8992)  time: 7.2073  data: 0.6542  max mem: 30315\n","Epoch: [4]  [ 690/2163]  eta: 2:57:05  lr: 0.000037  min_lr: 0.000002  loss: 0.2660 (0.2668)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0252 (11.8764)  time: 7.2099  data: 0.6563  max mem: 30315\n","Epoch: [4]  [ 700/2163]  eta: 2:55:52  lr: 0.000037  min_lr: 0.000002  loss: 0.2419 (0.2662)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.0901 (11.8293)  time: 7.2134  data: 0.6593  max mem: 30315\n","Epoch: [4]  [ 710/2163]  eta: 2:54:40  lr: 0.000037  min_lr: 0.000002  loss: 0.2069 (0.2667)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5599 (11.8514)  time: 7.2097  data: 0.6556  max mem: 30315\n","Epoch: [4]  [ 720/2163]  eta: 2:53:28  lr: 0.000036  min_lr: 0.000002  loss: 0.2333 (0.2671)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.0500 (11.8507)  time: 7.1991  data: 0.6444  max mem: 30315\n","Epoch: [4]  [ 730/2163]  eta: 2:52:15  lr: 0.000036  min_lr: 0.000002  loss: 0.2455 (0.2672)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6466 (11.8491)  time: 7.1943  data: 0.6392  max mem: 30315\n","Epoch: [4]  [ 740/2163]  eta: 2:51:03  lr: 0.000036  min_lr: 0.000002  loss: 0.2225 (0.2663)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8740 (11.8133)  time: 7.2033  data: 0.6482  max mem: 30315\n","Epoch: [4]  [ 750/2163]  eta: 2:49:51  lr: 0.000036  min_lr: 0.000002  loss: 0.2244 (0.2667)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8715 (11.8176)  time: 7.2047  data: 0.6497  max mem: 30315\n","Epoch: [4]  [ 760/2163]  eta: 2:48:38  lr: 0.000036  min_lr: 0.000002  loss: 0.2876 (0.2674)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.5776 (11.8228)  time: 7.2074  data: 0.6524  max mem: 30315\n","Epoch: [4]  [ 770/2163]  eta: 2:47:26  lr: 0.000035  min_lr: 0.000002  loss: 0.3173 (0.2681)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.0209 (11.8160)  time: 7.2056  data: 0.6506  max mem: 30315\n","Epoch: [4]  [ 780/2163]  eta: 2:46:14  lr: 0.000035  min_lr: 0.000002  loss: 0.2760 (0.2677)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8384 (11.7955)  time: 7.2071  data: 0.6520  max mem: 30315\n","Epoch: [4]  [ 790/2163]  eta: 2:45:02  lr: 0.000035  min_lr: 0.000002  loss: 0.2285 (0.2680)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8384 (11.8118)  time: 7.2156  data: 0.6607  max mem: 30315\n","Epoch: [4]  [ 800/2163]  eta: 2:43:50  lr: 0.000035  min_lr: 0.000002  loss: 0.2426 (0.2682)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0222 (11.7848)  time: 7.2172  data: 0.6629  max mem: 30315\n","Epoch: [4]  [ 810/2163]  eta: 2:42:38  lr: 0.000034  min_lr: 0.000002  loss: 0.3180 (0.2688)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0222 (11.7822)  time: 7.2257  data: 0.6713  max mem: 30315\n","Epoch: [4]  [ 820/2163]  eta: 2:41:26  lr: 0.000034  min_lr: 0.000002  loss: 0.3072 (0.2692)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5459 (11.7673)  time: 7.2348  data: 0.6801  max mem: 30315\n","Epoch: [4]  [ 830/2163]  eta: 2:40:14  lr: 0.000034  min_lr: 0.000002  loss: 0.2965 (0.2699)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.2097 (11.7522)  time: 7.2289  data: 0.6743  max mem: 30315\n","Epoch: [4]  [ 840/2163]  eta: 2:39:02  lr: 0.000034  min_lr: 0.000002  loss: 0.3234 (0.2707)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.0329 (11.7623)  time: 7.2215  data: 0.6641  max mem: 30315\n","Epoch: [4]  [ 850/2163]  eta: 2:37:51  lr: 0.000034  min_lr: 0.000002  loss: 0.3234 (0.2712)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.0329 (11.7720)  time: 7.2268  data: 0.6697  max mem: 30315\n","Epoch: [4]  [ 860/2163]  eta: 2:36:38  lr: 0.000033  min_lr: 0.000002  loss: 0.2794 (0.2711)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.9419 (11.7522)  time: 7.2141  data: 0.6599  max mem: 30315\n","Epoch: [4]  [ 870/2163]  eta: 2:35:26  lr: 0.000033  min_lr: 0.000002  loss: 0.2811 (0.2715)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8120 (11.7319)  time: 7.2092  data: 0.6547  max mem: 30315\n","Epoch: [4]  [ 880/2163]  eta: 2:34:14  lr: 0.000033  min_lr: 0.000002  loss: 0.2630 (0.2721)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8120 (11.7241)  time: 7.2075  data: 0.6530  max mem: 30315\n","Epoch: [4]  [ 890/2163]  eta: 2:33:02  lr: 0.000033  min_lr: 0.000002  loss: 0.2858 (0.2727)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5597 (11.7159)  time: 7.2151  data: 0.6603  max mem: 30315\n","Epoch: [4]  [ 900/2163]  eta: 2:31:50  lr: 0.000033  min_lr: 0.000002  loss: 0.2961 (0.2730)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4755 (11.6965)  time: 7.2297  data: 0.6745  max mem: 30315\n","Epoch: [4]  [ 910/2163]  eta: 2:30:38  lr: 0.000032  min_lr: 0.000002  loss: 0.2461 (0.2726)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.1849 (11.6800)  time: 7.2197  data: 0.6644  max mem: 30315\n","Epoch: [4]  [ 920/2163]  eta: 2:29:26  lr: 0.000032  min_lr: 0.000002  loss: 0.2217 (0.2721)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.6475 (11.6691)  time: 7.2076  data: 0.6523  max mem: 30315\n","Epoch: [4]  [ 930/2163]  eta: 2:28:14  lr: 0.000032  min_lr: 0.000002  loss: 0.2082 (0.2716)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3060 (11.6785)  time: 7.2130  data: 0.6582  max mem: 30315\n","Epoch: [4]  [ 940/2163]  eta: 2:27:01  lr: 0.000032  min_lr: 0.000002  loss: 0.1959 (0.2713)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3550 (11.6731)  time: 7.2189  data: 0.6639  max mem: 30315\n","Epoch: [4]  [ 950/2163]  eta: 2:25:49  lr: 0.000032  min_lr: 0.000002  loss: 0.2647 (0.2718)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6093 (11.6708)  time: 7.2156  data: 0.6602  max mem: 30315\n","Epoch: [4]  [ 960/2163]  eta: 2:24:37  lr: 0.000031  min_lr: 0.000002  loss: 0.3229 (0.2724)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2028 (11.6541)  time: 7.2169  data: 0.6615  max mem: 30315\n","Epoch: [4]  [ 970/2163]  eta: 2:23:25  lr: 0.000031  min_lr: 0.000002  loss: 0.2477 (0.2721)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.7793 (11.6367)  time: 7.2152  data: 0.6602  max mem: 30315\n","Epoch: [4]  [ 980/2163]  eta: 2:22:13  lr: 0.000031  min_lr: 0.000002  loss: 0.2304 (0.2720)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3218 (11.6312)  time: 7.2039  data: 0.6489  max mem: 30315\n","Epoch: [4]  [ 990/2163]  eta: 2:21:01  lr: 0.000031  min_lr: 0.000002  loss: 0.2542 (0.2720)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.6529 (11.6123)  time: 7.2092  data: 0.6537  max mem: 30315\n","Epoch: [4]  [1000/2163]  eta: 2:19:49  lr: 0.000031  min_lr: 0.000002  loss: 0.2542 (0.2721)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0115 (11.5963)  time: 7.2281  data: 0.6726  max mem: 30315\n","Epoch: [4]  [1010/2163]  eta: 2:18:37  lr: 0.000031  min_lr: 0.000002  loss: 0.2369 (0.2716)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1313 (11.5860)  time: 7.2175  data: 0.6619  max mem: 30315\n","Epoch: [4]  [1020/2163]  eta: 2:17:24  lr: 0.000030  min_lr: 0.000002  loss: 0.2369 (0.2716)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5172 (11.5844)  time: 7.2068  data: 0.6512  max mem: 30315\n","Epoch: [4]  [1030/2163]  eta: 2:16:12  lr: 0.000030  min_lr: 0.000002  loss: 0.2723 (0.2721)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2904 (11.5767)  time: 7.2028  data: 0.6474  max mem: 30315\n","Epoch: [4]  [1040/2163]  eta: 2:15:00  lr: 0.000030  min_lr: 0.000002  loss: 0.3001 (0.2728)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8608 (11.5690)  time: 7.2038  data: 0.6485  max mem: 30315\n","Epoch: [4]  [1050/2163]  eta: 2:13:48  lr: 0.000030  min_lr: 0.000001  loss: 0.3000 (0.2725)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1384 (11.5587)  time: 7.2212  data: 0.6657  max mem: 30315\n","Epoch: [4]  [1060/2163]  eta: 2:12:36  lr: 0.000030  min_lr: 0.000001  loss: 0.2958 (0.2736)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2429 (11.5636)  time: 7.2173  data: 0.6616  max mem: 30315\n","Epoch: [4]  [1070/2163]  eta: 2:11:24  lr: 0.000029  min_lr: 0.000001  loss: 0.3132 (0.2735)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.5774 (11.5400)  time: 7.2183  data: 0.6627  max mem: 30315\n","Epoch: [4]  [1080/2163]  eta: 2:10:12  lr: 0.000029  min_lr: 0.000001  loss: 0.2853 (0.2740)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.4233 (11.5209)  time: 7.2251  data: 0.6696  max mem: 30315\n","Epoch: [4]  [1090/2163]  eta: 2:09:00  lr: 0.000029  min_lr: 0.000001  loss: 0.2946 (0.2740)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7232 (11.5057)  time: 7.2148  data: 0.6596  max mem: 30315\n","Epoch: [4]  [1100/2163]  eta: 2:07:48  lr: 0.000029  min_lr: 0.000001  loss: 0.3048 (0.2746)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0652 (11.4981)  time: 7.2158  data: 0.6608  max mem: 30315\n","Epoch: [4]  [1110/2163]  eta: 2:06:35  lr: 0.000029  min_lr: 0.000001  loss: 0.3223 (0.2753)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7984 (11.5057)  time: 7.2214  data: 0.6663  max mem: 30315\n","Epoch: [4]  [1120/2163]  eta: 2:05:24  lr: 0.000029  min_lr: 0.000001  loss: 0.3068 (0.2753)  loss_scale: 32768.0000 (32768.0000)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7984 (11.4940)  time: 7.2350  data: 0.6766  max mem: 30315\n","Epoch: [4]  [1130/2163]  eta: 2:04:11  lr: 0.000028  min_lr: 0.000001  loss: 0.2576 (0.2752)  loss_scale: 32768.0000 (32941.8355)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4698 (11.4812)  time: 7.2263  data: 0.6677  max mem: 30315\n","Epoch: [4]  [1140/2163]  eta: 2:02:59  lr: 0.000028  min_lr: 0.000001  loss: 0.2816 (0.2762)  loss_scale: 65536.0000 (33227.4987)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0792 (11.4832)  time: 7.2080  data: 0.6523  max mem: 30315\n","Epoch: [4]  [1150/2163]  eta: 2:01:47  lr: 0.000028  min_lr: 0.000001  loss: 0.2749 (0.2758)  loss_scale: 65536.0000 (33508.1981)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3317 (11.4668)  time: 7.2146  data: 0.6590  max mem: 30315\n","Epoch: [4]  [1160/2163]  eta: 2:00:35  lr: 0.000028  min_lr: 0.000001  loss: 0.2515 (0.2768)  loss_scale: 65536.0000 (33784.0620)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7295 (11.4750)  time: 7.2233  data: 0.6676  max mem: 30315\n","Epoch: [4]  [1170/2163]  eta: 1:59:23  lr: 0.000028  min_lr: 0.000001  loss: 0.3060 (0.2770)  loss_scale: 65536.0000 (34055.2143)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7935 (11.4720)  time: 7.2265  data: 0.6707  max mem: 30315\n","Epoch: [4]  [1180/2163]  eta: 1:58:11  lr: 0.000028  min_lr: 0.000001  loss: 0.3003 (0.2774)  loss_scale: 65536.0000 (34321.7748)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7795 (11.4643)  time: 7.2274  data: 0.6713  max mem: 30315\n","Epoch: [4]  [1190/2163]  eta: 1:56:59  lr: 0.000028  min_lr: 0.000001  loss: 0.3003 (0.2776)  loss_scale: 65536.0000 (34583.8589)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.2647 (11.4471)  time: 7.2255  data: 0.6695  max mem: 30315\n","Epoch: [4]  [1200/2163]  eta: 1:55:47  lr: 0.000027  min_lr: 0.000001  loss: 0.2596 (0.2776)  loss_scale: 65536.0000 (34841.5787)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.2959 (11.4331)  time: 7.2303  data: 0.6743  max mem: 30315\n","Epoch: [4]  [1210/2163]  eta: 1:54:35  lr: 0.000027  min_lr: 0.000001  loss: 0.3080 (0.2781)  loss_scale: 65536.0000 (35095.0421)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0969 (11.4420)  time: 7.2268  data: 0.6709  max mem: 30315\n","Epoch: [4]  [1220/2163]  eta: 1:53:23  lr: 0.000027  min_lr: 0.000001  loss: 0.3045 (0.2780)  loss_scale: 65536.0000 (35344.3538)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7164 (11.4332)  time: 7.2220  data: 0.6663  max mem: 30315\n","Epoch: [4]  [1230/2163]  eta: 1:52:11  lr: 0.000027  min_lr: 0.000001  loss: 0.2606 (0.2783)  loss_scale: 65536.0000 (35589.6149)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0774 (11.4321)  time: 7.2226  data: 0.6674  max mem: 30315\n","NaN or Inf found in input tensor.\n","Epoch: [4]  [1240/2163]  eta: 1:50:59  lr: 0.000027  min_lr: 0.000001  loss: 0.2659 (0.2784)  loss_scale: 65536.0000 (35593.2828)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5179 (inf)  time: 7.2081  data: 0.6552  max mem: 30315\n","Epoch: [4]  [1250/2163]  eta: 1:49:46  lr: 0.000027  min_lr: 0.000001  loss: 0.2849 (0.2783)  loss_scale: 32768.0000 (35570.6986)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9388 (inf)  time: 7.2024  data: 0.6494  max mem: 30315\n","Epoch: [4]  [1260/2163]  eta: 1:48:34  lr: 0.000026  min_lr: 0.000001  loss: 0.3003 (0.2787)  loss_scale: 32768.0000 (35548.4726)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5142 (inf)  time: 7.2099  data: 0.6547  max mem: 30315\n","Epoch: [4]  [1270/2163]  eta: 1:47:22  lr: 0.000026  min_lr: 0.000001  loss: 0.2507 (0.2786)  loss_scale: 32768.0000 (35526.5964)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.4657 (inf)  time: 7.2174  data: 0.6621  max mem: 30315\n","Epoch: [4]  [1280/2163]  eta: 1:46:10  lr: 0.000026  min_lr: 0.000001  loss: 0.2796 (0.2788)  loss_scale: 32768.0000 (35505.0617)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7980 (inf)  time: 7.2223  data: 0.6670  max mem: 30315\n","Epoch: [4]  [1290/2163]  eta: 1:44:58  lr: 0.000026  min_lr: 0.000001  loss: 0.2869 (0.2788)  loss_scale: 32768.0000 (35483.8606)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0497 (inf)  time: 7.2272  data: 0.6717  max mem: 30315\n","Epoch: [4]  [1300/2163]  eta: 1:43:46  lr: 0.000026  min_lr: 0.000001  loss: 0.2527 (0.2790)  loss_scale: 32768.0000 (35462.9854)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.0497 (inf)  time: 7.2236  data: 0.6682  max mem: 30315\n","Epoch: [4]  [1310/2163]  eta: 1:42:34  lr: 0.000026  min_lr: 0.000001  loss: 0.3103 (0.2795)  loss_scale: 32768.0000 (35442.4287)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9303 (inf)  time: 7.2236  data: 0.6683  max mem: 30315\n","Epoch: [4]  [1320/2163]  eta: 1:41:22  lr: 0.000026  min_lr: 0.000001  loss: 0.2869 (0.2793)  loss_scale: 32768.0000 (35422.1832)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7097 (inf)  time: 7.2312  data: 0.6759  max mem: 30315\n","Epoch: [4]  [1330/2163]  eta: 1:40:10  lr: 0.000026  min_lr: 0.000001  loss: 0.2750 (0.2797)  loss_scale: 32768.0000 (35402.2419)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1294 (inf)  time: 7.2318  data: 0.6765  max mem: 30315\n","Epoch: [4]  [1340/2163]  eta: 1:38:58  lr: 0.000025  min_lr: 0.000001  loss: 0.3035 (0.2801)  loss_scale: 32768.0000 (35382.5981)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.4723 (inf)  time: 7.2317  data: 0.6762  max mem: 30315\n","Epoch: [4]  [1350/2163]  eta: 1:37:46  lr: 0.000025  min_lr: 0.000001  loss: 0.3035 (0.2803)  loss_scale: 32768.0000 (35363.2450)  weight_decay: 0.0100 (0.0100)  grad_norm: 12.4723 (inf)  time: 7.2292  data: 0.6740  max mem: 30315\n","Epoch: [4]  [1360/2163]  eta: 1:36:33  lr: 0.000025  min_lr: 0.000001  loss: 0.3089 (0.2806)  loss_scale: 32768.0000 (35344.1763)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9415 (inf)  time: 7.2224  data: 0.6672  max mem: 30315\n","Epoch: [4]  [1370/2163]  eta: 1:35:21  lr: 0.000025  min_lr: 0.000001  loss: 0.2496 (0.2807)  loss_scale: 32768.0000 (35325.3858)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5056 (inf)  time: 7.2258  data: 0.6707  max mem: 30315\n","Epoch: [4]  [1380/2163]  eta: 1:34:09  lr: 0.000025  min_lr: 0.000001  loss: 0.2680 (0.2807)  loss_scale: 32768.0000 (35306.8675)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3911 (inf)  time: 7.2273  data: 0.6722  max mem: 30315\n","Epoch: [4]  [1390/2163]  eta: 1:32:57  lr: 0.000025  min_lr: 0.000001  loss: 0.2819 (0.2811)  loss_scale: 32768.0000 (35288.6154)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.0088 (inf)  time: 7.2365  data: 0.6813  max mem: 30315\n","Epoch: [4]  [1400/2163]  eta: 1:31:45  lr: 0.000025  min_lr: 0.000001  loss: 0.2807 (0.2815)  loss_scale: 32768.0000 (35270.6238)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.6874 (inf)  time: 7.2401  data: 0.6849  max mem: 30315\n","Epoch: [4]  [1410/2163]  eta: 1:30:33  lr: 0.000025  min_lr: 0.000001  loss: 0.2725 (0.2815)  loss_scale: 32768.0000 (35252.8873)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3465 (inf)  time: 7.2238  data: 0.6686  max mem: 30315\n","Epoch: [4]  [1420/2163]  eta: 1:29:21  lr: 0.000024  min_lr: 0.000001  loss: 0.2746 (0.2817)  loss_scale: 32768.0000 (35235.4004)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.0767 (inf)  time: 7.2286  data: 0.6731  max mem: 30315\n","Epoch: [4]  [1430/2163]  eta: 1:28:09  lr: 0.000024  min_lr: 0.000001  loss: 0.2904 (0.2819)  loss_scale: 32768.0000 (35218.1579)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5100 (inf)  time: 7.2306  data: 0.6750  max mem: 30315\n","Epoch: [4]  [1440/2163]  eta: 1:26:57  lr: 0.000024  min_lr: 0.000001  loss: 0.3102 (0.2827)  loss_scale: 32768.0000 (35201.1548)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.2785 (inf)  time: 7.2251  data: 0.6695  max mem: 30315\n","Epoch: [4]  [1450/2163]  eta: 1:25:45  lr: 0.000024  min_lr: 0.000001  loss: 0.3450 (0.2828)  loss_scale: 32768.0000 (35184.3859)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.2785 (inf)  time: 7.2177  data: 0.6621  max mem: 30315\n","Epoch: [4]  [1460/2163]  eta: 1:24:32  lr: 0.000024  min_lr: 0.000001  loss: 0.3119 (0.2831)  loss_scale: 32768.0000 (35167.8467)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.6117 (inf)  time: 7.2163  data: 0.6613  max mem: 30315\n","Epoch: [4]  [1470/2163]  eta: 1:23:20  lr: 0.000024  min_lr: 0.000001  loss: 0.3039 (0.2831)  loss_scale: 32768.0000 (35151.5323)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.9940 (inf)  time: 7.2214  data: 0.6669  max mem: 30315\n","Epoch: [4]  [1480/2163]  eta: 1:22:08  lr: 0.000024  min_lr: 0.000001  loss: 0.2887 (0.2832)  loss_scale: 32768.0000 (35135.4382)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5478 (inf)  time: 7.2204  data: 0.6657  max mem: 30315\n","Epoch: [4]  [1490/2163]  eta: 1:20:56  lr: 0.000024  min_lr: 0.000001  loss: 0.2941 (0.2837)  loss_scale: 32768.0000 (35119.5600)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.9556 (inf)  time: 7.2214  data: 0.6664  max mem: 30315\n","Epoch: [4]  [1500/2163]  eta: 1:19:44  lr: 0.000024  min_lr: 0.000001  loss: 0.2789 (0.2835)  loss_scale: 32768.0000 (35103.8934)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8065 (inf)  time: 7.2241  data: 0.6687  max mem: 30315\n","Epoch: [4]  [1510/2163]  eta: 1:18:32  lr: 0.000023  min_lr: 0.000001  loss: 0.2789 (0.2840)  loss_scale: 32768.0000 (35088.4341)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8065 (inf)  time: 7.2200  data: 0.6648  max mem: 30315\n","Epoch: [4]  [1520/2163]  eta: 1:17:20  lr: 0.000023  min_lr: 0.000001  loss: 0.3174 (0.2840)  loss_scale: 32768.0000 (35073.1782)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1344 (inf)  time: 7.2157  data: 0.6602  max mem: 30315\n","Epoch: [4]  [1530/2163]  eta: 1:16:07  lr: 0.000023  min_lr: 0.000001  loss: 0.2834 (0.2840)  loss_scale: 32768.0000 (35058.1215)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4495 (inf)  time: 7.2174  data: 0.6619  max mem: 30315\n","Epoch: [4]  [1540/2163]  eta: 1:14:55  lr: 0.000023  min_lr: 0.000001  loss: 0.2812 (0.2839)  loss_scale: 32768.0000 (35043.2602)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8869 (inf)  time: 7.2187  data: 0.6635  max mem: 30315\n","NaN or Inf found in input tensor.\n","Epoch: [4]  [1550/2163]  eta: 1:13:43  lr: 0.000023  min_lr: 0.000001  loss: 0.2647 (0.2837)  loss_scale: 32768.0000 (34975.7730)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3205 (inf)  time: 7.2222  data: 0.6691  max mem: 30315\n","Epoch: [4]  [1560/2163]  eta: 1:12:31  lr: 0.000023  min_lr: 0.000001  loss: 0.2686 (0.2841)  loss_scale: 16384.0000 (34856.6714)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1861 (inf)  time: 7.2240  data: 0.6709  max mem: 30315\n","Epoch: [4]  [1570/2163]  eta: 1:11:19  lr: 0.000023  min_lr: 0.000001  loss: 0.2958 (0.2842)  loss_scale: 16384.0000 (34739.0859)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7700 (inf)  time: 7.2190  data: 0.6641  max mem: 30315\n","Epoch: [4]  [1580/2163]  eta: 1:10:07  lr: 0.000023  min_lr: 0.000001  loss: 0.2368 (0.2842)  loss_scale: 16384.0000 (34622.9880)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.4279 (inf)  time: 7.2165  data: 0.6619  max mem: 30315\n","Epoch: [4]  [1590/2163]  eta: 1:08:55  lr: 0.000023  min_lr: 0.000001  loss: 0.3126 (0.2844)  loss_scale: 16384.0000 (34508.3495)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.2101 (inf)  time: 7.2287  data: 0.6737  max mem: 30315\n","Epoch: [4]  [1600/2163]  eta: 1:07:42  lr: 0.000023  min_lr: 0.000001  loss: 0.3085 (0.2845)  loss_scale: 16384.0000 (34395.1430)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.3082 (inf)  time: 7.2287  data: 0.6732  max mem: 30315\n","Epoch: [4]  [1610/2163]  eta: 1:06:30  lr: 0.000022  min_lr: 0.000001  loss: 0.3236 (0.2847)  loss_scale: 16384.0000 (34283.3420)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5641 (inf)  time: 7.2287  data: 0.6732  max mem: 30315\n","Epoch: [4]  [1620/2163]  eta: 1:05:18  lr: 0.000022  min_lr: 0.000001  loss: 0.3236 (0.2849)  loss_scale: 16384.0000 (34172.9204)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.3192 (inf)  time: 7.2396  data: 0.6841  max mem: 30315\n","Epoch: [4]  [1630/2163]  eta: 1:04:06  lr: 0.000022  min_lr: 0.000001  loss: 0.3055 (0.2849)  loss_scale: 16384.0000 (34063.8529)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.7966 (inf)  time: 7.2383  data: 0.6827  max mem: 30315\n","Epoch: [4]  [1640/2163]  eta: 1:02:54  lr: 0.000022  min_lr: 0.000001  loss: 0.2608 (0.2849)  loss_scale: 16384.0000 (33956.1146)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9278 (inf)  time: 7.2334  data: 0.6779  max mem: 30315\n","Epoch: [4]  [1650/2163]  eta: 1:01:42  lr: 0.000022  min_lr: 0.000001  loss: 0.2924 (0.2853)  loss_scale: 16384.0000 (33849.6814)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9457 (inf)  time: 7.2348  data: 0.6795  max mem: 30315\n","Epoch: [4]  [1660/2163]  eta: 1:00:30  lr: 0.000022  min_lr: 0.000001  loss: 0.3011 (0.2854)  loss_scale: 16384.0000 (33744.5298)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2504 (inf)  time: 7.2286  data: 0.6733  max mem: 30315\n","Epoch: [4]  [1670/2163]  eta: 0:59:18  lr: 0.000022  min_lr: 0.000001  loss: 0.3011 (0.2855)  loss_scale: 16384.0000 (33640.6367)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.3787 (inf)  time: 7.2307  data: 0.6723  max mem: 30315\n","Epoch: [4]  [1680/2163]  eta: 0:58:06  lr: 0.000022  min_lr: 0.000001  loss: 0.3011 (0.2858)  loss_scale: 16384.0000 (33537.9798)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.1620 (inf)  time: 7.2361  data: 0.6778  max mem: 30315\n","Epoch: [4]  [1690/2163]  eta: 0:56:53  lr: 0.000022  min_lr: 0.000001  loss: 0.2822 (0.2857)  loss_scale: 16384.0000 (33436.5370)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2118 (inf)  time: 7.2251  data: 0.6702  max mem: 30315\n","Epoch: [4]  [1700/2163]  eta: 0:55:41  lr: 0.000022  min_lr: 0.000001  loss: 0.2530 (0.2860)  loss_scale: 16384.0000 (33336.2869)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.4461 (inf)  time: 7.2224  data: 0.6677  max mem: 30315\n","Epoch: [4]  [1710/2163]  eta: 0:54:29  lr: 0.000022  min_lr: 0.000001  loss: 0.2955 (0.2860)  loss_scale: 16384.0000 (33237.2086)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8047 (inf)  time: 7.2203  data: 0.6654  max mem: 30315\n","Epoch: [4]  [1720/2163]  eta: 0:53:17  lr: 0.000022  min_lr: 0.000001  loss: 0.2942 (0.2862)  loss_scale: 16384.0000 (33139.2818)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3635 (inf)  time: 7.2172  data: 0.6621  max mem: 30315\n","Epoch: [4]  [1730/2163]  eta: 0:52:05  lr: 0.000022  min_lr: 0.000001  loss: 0.2394 (0.2861)  loss_scale: 16384.0000 (33042.4864)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1499 (inf)  time: 7.2360  data: 0.6812  max mem: 30315\n","Epoch: [4]  [1740/2163]  eta: 0:50:53  lr: 0.000021  min_lr: 0.000001  loss: 0.2394 (0.2860)  loss_scale: 16384.0000 (32946.8030)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3423 (inf)  time: 7.2448  data: 0.6901  max mem: 30315\n","Epoch: [4]  [1750/2163]  eta: 0:49:40  lr: 0.000021  min_lr: 0.000001  loss: 0.2776 (0.2865)  loss_scale: 16384.0000 (32852.2125)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7654 (inf)  time: 7.2252  data: 0.6703  max mem: 30315\n","Epoch: [4]  [1760/2163]  eta: 0:48:28  lr: 0.000021  min_lr: 0.000001  loss: 0.2776 (0.2866)  loss_scale: 16384.0000 (32758.6962)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6465 (inf)  time: 7.2110  data: 0.6561  max mem: 30315\n","Epoch: [4]  [1770/2163]  eta: 0:47:16  lr: 0.000021  min_lr: 0.000001  loss: 0.3144 (0.2874)  loss_scale: 16384.0000 (32666.2360)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6734 (inf)  time: 7.2137  data: 0.6591  max mem: 30315\n","Epoch: [4]  [1780/2163]  eta: 0:46:04  lr: 0.000021  min_lr: 0.000001  loss: 0.3175 (0.2876)  loss_scale: 16384.0000 (32574.8141)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1634 (inf)  time: 7.2199  data: 0.6652  max mem: 30315\n","Epoch: [4]  [1790/2163]  eta: 0:44:52  lr: 0.000021  min_lr: 0.000001  loss: 0.3166 (0.2881)  loss_scale: 16384.0000 (32484.4132)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.6127 (inf)  time: 7.2200  data: 0.6650  max mem: 30315\n","Epoch: [4]  [1800/2163]  eta: 0:43:40  lr: 0.000021  min_lr: 0.000001  loss: 0.2884 (0.2879)  loss_scale: 16384.0000 (32395.0161)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1387 (inf)  time: 7.2090  data: 0.6541  max mem: 30315\n","Epoch: [4]  [1810/2163]  eta: 0:42:27  lr: 0.000021  min_lr: 0.000001  loss: 0.2803 (0.2883)  loss_scale: 16384.0000 (32306.6063)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.0325 (inf)  time: 7.2181  data: 0.6634  max mem: 30315\n","Epoch: [4]  [1820/2163]  eta: 0:41:15  lr: 0.000021  min_lr: 0.000001  loss: 0.3483 (0.2888)  loss_scale: 16384.0000 (32219.1675)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1834 (inf)  time: 7.2350  data: 0.6801  max mem: 30315\n","Epoch: [4]  [1830/2163]  eta: 0:40:03  lr: 0.000021  min_lr: 0.000001  loss: 0.3445 (0.2892)  loss_scale: 16384.0000 (32132.6838)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.1834 (inf)  time: 7.2295  data: 0.6744  max mem: 30315\n","Epoch: [4]  [1840/2163]  eta: 0:38:51  lr: 0.000021  min_lr: 0.000001  loss: 0.2988 (0.2895)  loss_scale: 16384.0000 (32047.1396)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9227 (inf)  time: 7.2215  data: 0.6666  max mem: 30315\n","Epoch: [4]  [1850/2163]  eta: 0:37:39  lr: 0.000021  min_lr: 0.000001  loss: 0.2869 (0.2893)  loss_scale: 16384.0000 (31962.5197)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.3875 (inf)  time: 7.2186  data: 0.6643  max mem: 30315\n","Epoch: [4]  [1860/2163]  eta: 0:36:27  lr: 0.000021  min_lr: 0.000001  loss: 0.3257 (0.2899)  loss_scale: 16384.0000 (31878.8092)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.5256 (inf)  time: 7.2202  data: 0.6662  max mem: 30315\n","Epoch: [4]  [1870/2163]  eta: 0:35:14  lr: 0.000021  min_lr: 0.000001  loss: 0.3293 (0.2902)  loss_scale: 16384.0000 (31795.9936)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.8988 (inf)  time: 7.2278  data: 0.6738  max mem: 30315\n","Epoch: [4]  [1880/2163]  eta: 0:34:02  lr: 0.000021  min_lr: 0.000001  loss: 0.2972 (0.2904)  loss_scale: 16384.0000 (31714.0585)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.3505 (inf)  time: 7.2262  data: 0.6719  max mem: 30315\n","Epoch: [4]  [1890/2163]  eta: 0:32:50  lr: 0.000021  min_lr: 0.000001  loss: 0.2652 (0.2902)  loss_scale: 16384.0000 (31632.9900)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4645 (inf)  time: 7.2263  data: 0.6718  max mem: 30315\n","Epoch: [4]  [1900/2163]  eta: 0:31:38  lr: 0.000021  min_lr: 0.000001  loss: 0.2518 (0.2902)  loss_scale: 16384.0000 (31552.7743)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8573 (inf)  time: 7.2343  data: 0.6797  max mem: 30315\n","Epoch: [4]  [1910/2163]  eta: 0:30:26  lr: 0.000021  min_lr: 0.000001  loss: 0.2770 (0.2905)  loss_scale: 16384.0000 (31473.3982)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.2519 (inf)  time: 7.2370  data: 0.6822  max mem: 30315\n","Epoch: [4]  [1920/2163]  eta: 0:29:14  lr: 0.000020  min_lr: 0.000001  loss: 0.2770 (0.2905)  loss_scale: 16384.0000 (31394.8485)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3063 (inf)  time: 7.2327  data: 0.6778  max mem: 30315\n","Epoch: [4]  [1930/2163]  eta: 0:28:01  lr: 0.000020  min_lr: 0.000001  loss: 0.3003 (0.2908)  loss_scale: 16384.0000 (31317.1124)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.2472 (inf)  time: 7.2339  data: 0.6788  max mem: 30315\n","Epoch: [4]  [1940/2163]  eta: 0:26:49  lr: 0.000020  min_lr: 0.000001  loss: 0.2840 (0.2909)  loss_scale: 16384.0000 (31240.1772)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8333 (inf)  time: 7.2386  data: 0.6837  max mem: 30315\n","Epoch: [4]  [1950/2163]  eta: 0:25:37  lr: 0.000020  min_lr: 0.000001  loss: 0.2691 (0.2912)  loss_scale: 16384.0000 (31164.0308)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6562 (inf)  time: 7.2305  data: 0.6727  max mem: 30315\n","Epoch: [4]  [1960/2163]  eta: 0:24:25  lr: 0.000020  min_lr: 0.000001  loss: 0.2691 (0.2914)  loss_scale: 16384.0000 (31088.6609)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.6562 (inf)  time: 7.2237  data: 0.6657  max mem: 30315\n","Epoch: [4]  [1970/2163]  eta: 0:23:13  lr: 0.000020  min_lr: 0.000001  loss: 0.2645 (0.2915)  loss_scale: 16384.0000 (31014.0558)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4351 (inf)  time: 7.2217  data: 0.6671  max mem: 30315\n","Epoch: [4]  [1980/2163]  eta: 0:22:01  lr: 0.000020  min_lr: 0.000001  loss: 0.2732 (0.2917)  loss_scale: 16384.0000 (30940.2039)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4351 (inf)  time: 7.2308  data: 0.6764  max mem: 30315\n","Epoch: [4]  [1990/2163]  eta: 0:20:48  lr: 0.000020  min_lr: 0.000001  loss: 0.2552 (0.2915)  loss_scale: 16384.0000 (30867.0939)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4217 (inf)  time: 7.2288  data: 0.6740  max mem: 30315\n","Epoch: [4]  [2000/2163]  eta: 0:19:36  lr: 0.000020  min_lr: 0.000001  loss: 0.2439 (0.2912)  loss_scale: 16384.0000 (30794.7146)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.0402 (inf)  time: 7.2168  data: 0.6618  max mem: 30315\n","Epoch: [4]  [2010/2163]  eta: 0:18:24  lr: 0.000020  min_lr: 0.000001  loss: 0.2386 (0.2913)  loss_scale: 16384.0000 (30723.0552)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.0153 (inf)  time: 7.2117  data: 0.6567  max mem: 30315\n","Epoch: [4]  [2020/2163]  eta: 0:17:12  lr: 0.000020  min_lr: 0.000001  loss: 0.2316 (0.2911)  loss_scale: 16384.0000 (30652.1049)  weight_decay: 0.0100 (0.0100)  grad_norm: 7.2250 (inf)  time: 7.2206  data: 0.6661  max mem: 30315\n","Epoch: [4]  [2030/2163]  eta: 0:16:00  lr: 0.000020  min_lr: 0.000001  loss: 0.2364 (0.2911)  loss_scale: 16384.0000 (30581.8533)  weight_decay: 0.0100 (0.0100)  grad_norm: 7.8796 (inf)  time: 7.2309  data: 0.6768  max mem: 30315\n","Epoch: [4]  [2040/2163]  eta: 0:14:47  lr: 0.000020  min_lr: 0.000001  loss: 0.2916 (0.2913)  loss_scale: 16384.0000 (30512.2901)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.5296 (inf)  time: 7.2220  data: 0.6679  max mem: 30315\n","Epoch: [4]  [2050/2163]  eta: 0:13:35  lr: 0.000020  min_lr: 0.000001  loss: 0.3129 (0.2913)  loss_scale: 16384.0000 (30443.4052)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.8001 (inf)  time: 7.2104  data: 0.6560  max mem: 30315\n","Epoch: [4]  [2060/2163]  eta: 0:12:23  lr: 0.000020  min_lr: 0.000001  loss: 0.3146 (0.2916)  loss_scale: 16384.0000 (30375.1887)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.2242 (inf)  time: 7.2215  data: 0.6668  max mem: 30315\n","Epoch: [4]  [2070/2163]  eta: 0:11:11  lr: 0.000020  min_lr: 0.000001  loss: 0.3036 (0.2918)  loss_scale: 16384.0000 (30307.6311)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.9613 (inf)  time: 7.2267  data: 0.6722  max mem: 30315\n","Epoch: [4]  [2080/2163]  eta: 0:09:59  lr: 0.000020  min_lr: 0.000001  loss: 0.2659 (0.2917)  loss_scale: 16384.0000 (30240.7227)  weight_decay: 0.0100 (0.0100)  grad_norm: 8.7646 (inf)  time: 7.2229  data: 0.6686  max mem: 30315\n","Epoch: [4]  [2090/2163]  eta: 0:08:46  lr: 0.000020  min_lr: 0.000001  loss: 0.2857 (0.2919)  loss_scale: 16384.0000 (30174.4543)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7544 (inf)  time: 7.2308  data: 0.6763  max mem: 30315\n","Epoch: [4]  [2100/2163]  eta: 0:07:34  lr: 0.000020  min_lr: 0.000001  loss: 0.2779 (0.2918)  loss_scale: 16384.0000 (30108.8168)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.8464 (inf)  time: 7.2288  data: 0.6741  max mem: 30315\n","Epoch: [4]  [2110/2163]  eta: 0:06:22  lr: 0.000020  min_lr: 0.000001  loss: 0.2719 (0.2921)  loss_scale: 16384.0000 (30043.8010)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.4661 (inf)  time: 7.2204  data: 0.6656  max mem: 30315\n","Epoch: [4]  [2120/2163]  eta: 0:05:10  lr: 0.000020  min_lr: 0.000001  loss: 0.3293 (0.2923)  loss_scale: 16384.0000 (29979.3984)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.7065 (inf)  time: 7.2222  data: 0.6676  max mem: 30315\n","Epoch: [4]  [2130/2163]  eta: 0:03:58  lr: 0.000020  min_lr: 0.000001  loss: 0.3166 (0.2926)  loss_scale: 16384.0000 (29915.6002)  weight_decay: 0.0100 (0.0100)  grad_norm: 10.1291 (inf)  time: 7.2241  data: 0.6693  max mem: 30315\n","Epoch: [4]  [2140/2163]  eta: 0:02:46  lr: 0.000020  min_lr: 0.000001  loss: 0.2938 (0.2928)  loss_scale: 16384.0000 (29852.3979)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.3964 (inf)  time: 7.2241  data: 0.6692  max mem: 30315\n","Epoch: [4]  [2150/2163]  eta: 0:01:33  lr: 0.000020  min_lr: 0.000001  loss: 0.2907 (0.2928)  loss_scale: 16384.0000 (29789.7834)  weight_decay: 0.0100 (0.0100)  grad_norm: 9.1671 (inf)  time: 7.2238  data: 0.6690  max mem: 30315\n","Epoch: [4]  [2160/2163]  eta: 0:00:21  lr: 0.000020  min_lr: 0.000001  loss: 0.3603 (0.2940)  loss_scale: 16384.0000 (29727.7483)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.0141 (inf)  time: 7.2224  data: 0.6674  max mem: 30315\n","Epoch: [4]  [2162/2163]  eta: 0:00:07  lr: 0.000020  min_lr: 0.000001  loss: 0.3422 (0.2941)  loss_scale: 16384.0000 (29715.4101)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4313 (inf)  time: 7.2216  data: 0.6665  max mem: 30315\n","Epoch: [4] Total time: 4:20:15 (7.2192 s / it)\n","Averaged stats: lr: 0.000020  min_lr: 0.000001  loss: 0.3422 (0.2941)  loss_scale: 16384.0000 (29715.4101)  weight_decay: 0.0100 (0.0100)  grad_norm: 11.4313 (inf)\n","/content/drive/MyDrive/멀티모달/github_folder/DACON_VQA/BEiT-3/engine_for_finetuning.py:592: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","Test:  [ 0/22]  eta: 0:01:02  score: 85.9375 (85.9375)  time: 2.8495  data: 0.6970  max mem: 30315\n","Test:  [10/22]  eta: 0:00:33  score: 87.5000 (88.2102)  time: 2.8004  data: 0.6967  max mem: 30315\n","Test:  [20/22]  eta: 0:00:05  score: 87.5000 (87.4256)  time: 2.8012  data: 0.7023  max mem: 30315\n","Test:  [21/22]  eta: 0:00:02  score: 87.5000 (87.5000)  time: 2.8016  data: 0.7027  max mem: 30315\n","Test: Total time: 0:01:01 (2.8044 s / it)\n","* Score 87.500\n","Performance of the network on the 1414 val images: 87.5%\n","Max performance: 87.50%\n","Training time 4:23:56\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["PHQeqP1vFiNa","ilGgur4jegfr","-OS9wn2W8ovn","AsjtB3_F891Z","xkUw73Sq9OfV"],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}